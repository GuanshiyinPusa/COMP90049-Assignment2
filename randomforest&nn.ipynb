{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "cqNmxQM_P4M8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import joblib\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"car_data.csv\")\n",
        "#print(df)\n",
        "#print(df.head())\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop(columns=[\"car_price\"])\n",
        "y = df[\"car_price\"]\n",
        "\n",
        "# Identify categorical and numeric columns\n",
        "categorical = [\"car_brand\", \"car_model\", \"car_city\", \"car_fuel\", \"car_transmission\", \"car_drive\", \"car_country\"]\n",
        "numeric = [\"car_mileage\", \"car_engine_capacity\", \"car_engine_hp\", \"car_age\"]\n",
        "\n",
        "# Define preprocessor. One-hot encode the categorical data.\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical)\n",
        "], remainder=\"passthrough\")\n",
        "\n",
        "# Split into train/test sets, can't use stratification because the target is continuous\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Random Forest Regressor to build the model\n",
        "model = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict prices for the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the MAE which is the average value of how far away the predicted price is from the real one\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
        "print(f\"R² Score: {r2:.10f}\")\n",
        "\n",
        "# new Mean Absolute Error: 204540.00 #n estimators = 100, max depth = inf\n",
        "# R² Score: 0.9049410372\n",
        "\n",
        "# Save the trained model to a file so that it doesn't need to be trained again\n",
        "joblib.dump(model, \"car_price_rf.pkl\")"
      ],
      "metadata": {
        "id": "WXtpLvjMFVL8",
        "outputId": "8ecf7b78-a38b-4e46-aa64-23ad3d46cc8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 288.46\n",
            "R² Score: 0.9985139782\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['car_price_rf.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "import joblib\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "path = kagglehub.dataset_download(\"volkanastasia/dataset-of-used-cars\")\n",
        "csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
        "csv_file = csv_files[0]\n",
        "# Load dataset\n",
        "df = pd.read_csv(f\"{path}/{csv_file}\")\n",
        "print(f\"✓ Dataset loaded: {df.shape[0]} rows\")\n",
        "#print(df)\n",
        "#print(df.head())\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop(columns=[\"car_price\"])\n",
        "y = df[\"car_price\"]\n",
        "\n",
        "# Identify categorical and numeric columns\n",
        "categorical = [\"car_brand\", \"car_model\", \"car_city\", \"car_fuel\", \"car_transmission\", \"car_drive\", \"car_country\"]\n",
        "numeric = [\"car_mileage\", \"car_engine_capacity\", \"car_engine_hp\", \"car_age\"]\n",
        "\n",
        "# Define preprocessor. One-hot encode the categorical data.\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical)\n",
        "], remainder=\"passthrough\")\n",
        "\n",
        "# Split into train/test sets, can't use stratification because the target is continuous\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Random Forest Regressor to build the model\n",
        "model = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict prices for the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the MAE which is the average value of how far away the predicted price is from the real one\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
        "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
        "print(f\"R² Score: {r2:.10f}\")\n",
        "\n",
        "# new Mean Absolute Error: 204540.00 #n estimators = 100, max depth = inf\n",
        "# R² Score: 0.9049410372\n",
        "\n",
        "# Save the trained model to a file so that it doesn't need to be trained again\n",
        "joblib.dump(model, \"car_price_rf.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oiF1BCDO8gL",
        "outputId": "e5e1a1ef-aca9-4fe5-ac9d-3b09fb25281a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'dataset-of-used-cars' dataset.\n",
            "✓ Dataset loaded: 42089 rows\n",
            "Mean Absolute Error: 199218.40\n",
            "Root Mean Squared Error: 442819.80\n",
            "R² Score: 0.9377565064\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['car_price_rf.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import joblib\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "path = kagglehub.dataset_download(\"volkanastasia/dataset-of-used-cars\")\n",
        "csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
        "csv_file = csv_files[0]\n",
        "df = pd.read_csv(f\"{path}/{csv_file}\")\n",
        "print(f\"✓ Dataset loaded: {df.shape[0]} rows\")\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop(columns=[\"car_price\"])\n",
        "y = df[\"car_price\"]\n",
        "\n",
        "# Identify categorical and numeric columns\n",
        "categorical = [\"car_brand\", \"car_model\", \"car_city\", \"car_fuel\", \"car_transmission\", \"car_drive\", \"car_country\"]\n",
        "numeric = [\"car_mileage\", \"car_engine_capacity\", \"car_engine_hp\", \"car_age\"]\n",
        "\n",
        "# Define preprocessor. One-Hot encoding because there are categorical features\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
        "    (\"num\", StandardScaler(), numeric)  # Scale numeric features for NN\n",
        "])\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Neural Network Regressor\n",
        "nn_model = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", MLPRegressor(\n",
        "        hidden_layer_sizes=(100, 50),  # Two hidden layers: 100 neurons -> 50 neurons\n",
        "        activation='relu',\n",
        "        solver='adam',\n",
        "        alpha=0.001,  # L2 regularization parameter\n",
        "        learning_rate='adaptive',\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "nn_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict prices for the test set\n",
        "y_pred = nn_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
        "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
        "print(f\"R² Score: {r2:.10f}\")\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(nn_model, \"car_price_nn.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnItPpnHPuIC",
        "outputId": "9d4b2481-2e2d-495f-ad3e-739a96d54bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'dataset-of-used-cars' dataset.\n",
            "✓ Dataset loaded: 42089 rows\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 196505.75\n",
            "Root Mean Squared Error: 463982.88\n",
            "R² Score: 0.9316649049\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['car_price_nn.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network MLPRegressor() (Multi-layer Perceptron)"
      ],
      "metadata": {
        "id": "eKiQU9dsQFVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import joblib\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"car_data.csv\")\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop(columns=[\"car_price\"])\n",
        "y = df[\"car_price\"]\n",
        "\n",
        "# Identify categorical and numeric columns\n",
        "categorical = [\"car_brand\", \"car_model\", \"car_city\", \"car_fuel\", \"car_transmission\", \"car_drive\", \"car_country\"]\n",
        "numeric = [\"car_mileage\", \"car_engine_capacity\", \"car_engine_hp\", \"car_age\"]\n",
        "\n",
        "# Define preprocessor. One-Hot encoding because there are categorical features\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
        "    (\"num\", StandardScaler(), numeric)  # Scale numeric features for NN\n",
        "])\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Neural Network Regressor\n",
        "nn_model = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", MLPRegressor(\n",
        "        hidden_layer_sizes=(100, 50),  # Two hidden layers: 100 neurons -> 50 neurons\n",
        "        activation='relu',\n",
        "        solver='adam',\n",
        "        alpha=0.001,  # L2 regularization parameter\n",
        "        learning_rate='adaptive',\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "nn_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict prices for the test set\n",
        "y_pred = nn_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
        "print(f\"R² Score: {r2:.10f}\")\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(nn_model, \"car_price_nn.pkl\")\n",
        "\n",
        "# Mean Absolute Error: 196505.75\n",
        "# R² Score: 0.9316649049"
      ],
      "metadata": {
        "id": "bxzqy6snQa5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run some data to see output"
      ],
      "metadata": {
        "id": "KpodlZb_RJL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load the saved model\n",
        "model = joblib.load(\"car_price_rf.pkl\")\n",
        "\n",
        "# Example input\n",
        "new_car = pd.DataFrame([{\n",
        "    \"Manufacturer\": \"Toyota\",\n",
        "    \"Model\": \"Corolla\",\n",
        "    \"Engine size\": 1.8,\n",
        "    \"Fuel type\": \"Petrol\",\n",
        "    \"Year of manufacture\": 2018,\n",
        "    \"Mileage\": 45000\n",
        "}])\n",
        "\n",
        "# Predict the price\n",
        "predicted_price = model.predict(new_car)\n",
        "print(f\"Predicted Price: ${predicted_price[0]:,.2f}\")\n",
        "\n",
        "# Predicted Price for rf: $38,596.89\n",
        "# Predicted Price for nn: $34,668.41"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "eYGrrkP3RNqr",
        "outputId": "77157469-281b-470c-f5eb-b03552eece80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "EOF: reading array data, expected 262144 bytes got 137456",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3809459602.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"car_price_rf.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Example input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0;31m# it has been written with. Other arrays are coerced to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 \u001b[0;31m# native endianness of the host system.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m                 obj = _unpickle(\n\u001b[0m\u001b[1;32m    750\u001b[0m                     \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                     \u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, ensure_native_byte_order, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             warnings.warn(\n",
            "\u001b[0;32m/usr/lib/python3.12/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1254\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0m_array_payload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                 \u001b[0m_array_payload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_array_payload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, unpickler, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# Manage array subclass case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(self, unpickler, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0mread_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_read_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mread_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_count\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m                 array[i : i + read_count] = unpickler.np.frombuffer(\n\u001b[1;32m    199\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle_utils.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"EOF: reading %s, expected %d bytes got %d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merror_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: EOF: reading array data, expected 262144 bytes got 137456"
          ]
        }
      ]
    }
  ]
}